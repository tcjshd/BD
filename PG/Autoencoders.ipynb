{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle(r, θ):\n",
    "    x = r * np.cos(θ)\n",
    "    y = r * np.sin(θ)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.008842531205746114, 0.02761907014736295],\n",
       " [1.5986899082860075, -0.5896486210070966],\n",
       " [-0.0570285556530223, -0.07346823836375693],\n",
       " [-0.008302338999917608, 0.09100010524136315],\n",
       " [-0.5349208899207861, -0.218688533467988]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "for i in range(1000):\n",
    "    θ = np.random.uniform(0, 2*np.pi)\n",
    "    r = np.random.randn()\n",
    "    x, y = (circle(r, θ))\n",
    "    train.append([x, y])\n",
    "train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00884253,  0.02761907],\n",
       "       [ 1.59868991, -0.58964862],\n",
       "       [-0.05702856, -0.07346824],\n",
       "       ...,\n",
       "       [ 0.63993958, -0.43692145],\n",
       "       [-0.09113293, -0.19439704],\n",
       "       [-0.4786428 , -0.10114104]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.array(train)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_train(train):\n",
    "    scaled_train = StandardScaler().fit_transform(train)\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(scaled_train)\n",
    "    train_pca = pca.transform(scaled_train)\n",
    "    inversed = pca.inverse_transform(train_pca)\n",
    "\n",
    "    mse = ((train - inversed) ** 2).mean(axis=None)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./autoencoder.png\" height=\"768\" width=\"1024\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def encoder(data, weights, bias):\n",
    "    return tanh(np.dot(data, weights) + bias)\n",
    "\n",
    "def decoder(data, weights, bias):\n",
    "    return tanh(np.dot(data, weights) + bias)\n",
    "\n",
    "input_dim = train.shape[1]   # 2\n",
    "latent_dim1 = 1              # first bottleneck\n",
    "latent_dim2 = 1              # hidden layer (optional deeper level)\n",
    "\n",
    "# Encoder weights\n",
    "we1 = np.random.randn(input_dim, latent_dim1)     # (2,1)\n",
    "be1 = np.random.randn(latent_dim1)\n",
    "\n",
    "we2 = np.random.randn(latent_dim1, latent_dim2)   # (1,1)\n",
    "be2 = np.random.randn(latent_dim2)\n",
    "\n",
    "# Decoder weights\n",
    "wd1 = np.random.randn(latent_dim2, latent_dim1)   # (1,1)\n",
    "bd1 = np.random.randn(latent_dim1)\n",
    "\n",
    "wd2 = np.random.randn(latent_dim1, input_dim)     # (1,2)\n",
    "bd2 = np.random.randn(input_dim)\n",
    "\n",
    "def forward_pass(train_data, we1, be1, we2, be2, wd1, bd1, wd2, bd2):\n",
    "    print(\"Input shape:\", train_data.shape)\n",
    "    z1 = encoder(train_data, we1, be1)   # (1000, 1)\n",
    "    print(\"Encoder 1 shape:\", z1.shape)\n",
    "    z2 = encoder(z1, we2, be2)           # (1000, 1)\n",
    "    print(\"Encoder 2 shape:\", z2.shape)\n",
    "    z3 = encoder(z2, wd1, bd1)           # (1000, 1)\n",
    "    print(\"Bottleneck shape:\", z3.shape)\n",
    "    output = decoder(z3, wd2, bd2)       # (1000, 2)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "\n",
    "    mse = ((train_data - output) ** 2).mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1000, 2)\n",
      "Encoder 1 shape: (1000, 1)\n",
      "Encoder 2 shape: (1000, 1)\n",
      "Bottleneck shape: (1000, 1)\n",
      "Output shape: (1000, 2)\n",
      "MSE (Autoencoder): 0.8904275102325788\n",
      "MSE (PCA): 0.2859627482660504\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE (Autoencoder): {forward_pass(train, we1, be1, we2, be2, wd1, bd1, wd2, bd2)}')\n",
    "print(f'MSE (PCA): {PCA_train(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------- Activation & Derivative -----------------------------\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "# ----------------------------- Forward & Backward Functions -----------------------------\n",
    "def forward(data, we1, be1, we2, be2, wd1, bd1, wd2, bd2):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(data, we1) + be1\n",
    "    a1 = tanh(z1)\n",
    "    \n",
    "    z2 = np.dot(a1, we2) + be2\n",
    "    a2 = tanh(z2)\n",
    "    \n",
    "    z3 = np.dot(a2, wd1) + bd1\n",
    "    a3 = tanh(z3)\n",
    "    \n",
    "    z4 = np.dot(a3, wd2) + bd2\n",
    "    output = tanh(z4)\n",
    "    \n",
    "    return z1, a1, z2, a2, z3, a3, z4, output\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "# ----------------------------- Training Function -----------------------------\n",
    "def train_autoencoder(train_data, lr=0.01, epochs=1000):\n",
    "    input_dim = train_data.shape[1]\n",
    "    latent_dim1 = 1\n",
    "    latent_dim2 = 1\n",
    "    \n",
    "    # Initialize weights and biases\n",
    "    we1 = np.random.randn(input_dim, latent_dim1)\n",
    "    be1 = np.zeros(latent_dim1)\n",
    "\n",
    "    we2 = np.random.randn(latent_dim1, latent_dim2)\n",
    "    be2 = np.zeros(latent_dim2)\n",
    "\n",
    "    wd1 = np.random.randn(latent_dim2, latent_dim1)\n",
    "    bd1 = np.zeros(latent_dim1)\n",
    "\n",
    "    wd2 = np.random.randn(latent_dim1, input_dim)\n",
    "    bd2 = np.zeros(input_dim)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward\n",
    "        z1, a1, z2, a2, z3, a3, z4, output = forward(train_data, we1, be1, we2, be2, wd1, bd1, wd2, bd2)\n",
    "        \n",
    "        # Loss\n",
    "        loss = compute_loss(train_data, output)\n",
    "        \n",
    "        # --------------------- Backward Pass ---------------------\n",
    "        # Output layer\n",
    "        d_output = 2 * (output - train_data) * tanh_derivative(z4)      # (N, 2)\n",
    "        d_wd2 = np.dot(a3.T, d_output) / len(train_data)\n",
    "        d_bd2 = d_output.mean(axis=0)\n",
    "\n",
    "        # Decoder1\n",
    "        d_a3 = np.dot(d_output, wd2.T) * tanh_derivative(z3)           # (N, 1)\n",
    "        d_wd1 = np.dot(a2.T, d_a3) / len(train_data)\n",
    "        d_bd1 = d_a3.mean(axis=0)\n",
    "\n",
    "        # Encoder2\n",
    "        d_a2 = np.dot(d_a3, wd1.T) * tanh_derivative(z2)               # (N, 1)\n",
    "        d_we2 = np.dot(a1.T, d_a2) / len(train_data)\n",
    "        d_be2 = d_a2.mean(axis=0)\n",
    "\n",
    "        # Encoder1\n",
    "        d_a1 = np.dot(d_a2, we2.T) * tanh_derivative(z1)               # (N, 2)\n",
    "        d_we1 = np.dot(train_data.T, d_a1) / len(train_data)\n",
    "        d_be1 = d_a1.mean(axis=0)\n",
    "        \n",
    "        # --------------------- Parameter Update ---------------------\n",
    "        we1 -= lr * d_we1\n",
    "        be1 -= lr * d_be1\n",
    "        we2 -= lr * d_we2\n",
    "        be2 -= lr * d_be2\n",
    "        wd1 -= lr * d_wd1\n",
    "        bd1 -= lr * d_bd1\n",
    "        wd2 -= lr * d_wd2\n",
    "        bd2 -= lr * d_bd2\n",
    "\n",
    "        # Optional: Print loss\n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.6f}\")\n",
    "\n",
    "    return we1, be1, we2, be2, wd1, bd1, wd2, bd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - Loss: 0.643577\n",
      "Epoch 101/1000 - Loss: 0.311584\n",
      "Epoch 201/1000 - Loss: 0.305163\n",
      "Epoch 301/1000 - Loss: 0.300358\n",
      "Epoch 401/1000 - Loss: 0.295409\n",
      "Epoch 501/1000 - Loss: 0.290490\n",
      "Epoch 601/1000 - Loss: 0.285871\n",
      "Epoch 701/1000 - Loss: 0.281734\n",
      "Epoch 801/1000 - Loss: 0.278232\n",
      "Epoch 901/1000 - Loss: 0.275460\n",
      "Epoch 1000/1000 - Loss: 0.273382\n"
     ]
    }
   ],
   "source": [
    "trained_params = train_autoencoder(train, lr=0.05, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Autoencoder): 0.273363818066893\n",
      "MSE (PCA): 0.2859627482660504\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE (Autoencoder): {forward_pass(train, *trained_params)}')\n",
    "print(f'MSE (PCA): {PCA_train(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
