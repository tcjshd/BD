{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOB17LaIFLqUvaWQLdue9Yc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from sklearn.preprocessing import OneHotEncoder\n","\n","sentences = [\n","    \"I love this movie\",\n","    \"This film is amazing\",\n","    \"I really liked the story\",\n","    \"It was a fantastic experience\",\n","    \"I hate this movie\",\n","    \"The film was terrible\",\n","    \"I really disliked the story\",\n","    \"It was a horrible experience\"\n","]\n","labels = [1, 1, 1, 1, 0, 0, 0, 0] # 1 for positive, 0 for negative/neutral\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","sequences = tokenizer.texts_to_sequences(sentences)\n","\n","max_length = max([len(seq) for seq in sequences])\n","padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n","\n","labels = np.array(labels).reshape(-1, 1)\n","encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","encoded_labels = encoder.fit_transform(labels)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 10\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n","model.add(SimpleRNN(32))\n","model.add(Dense(2, activation='softmax')) # Output layer for binary classification\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(padded_sequences, encoded_labels, epochs=10)\n","\n","new_sentences = [\"This is a amazing film.\", \"I hate this story.\"]\n","new_sequences = tokenizer.texts_to_sequences(new_sentences)\n","new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length, padding='post')\n","predictions = model.predict(new_padded_sequences)\n","\n","for i, prediction in enumerate(predictions):\n","  predicted_class = np.argmax(prediction) # 0 or 1\n","  print(f\"Sentence: {new_sentences[i]}, Predicted Class: {predicted_class}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBvruJOAO_Qc","executionInfo":{"status":"ok","timestamp":1740723981256,"user_tz":-330,"elapsed":2943,"user":{"displayName":"Dragon Rider","userId":"18245359096310103758"}},"outputId":"fe9b6686-992f-4485-8ed1-292845439b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3750 - loss: 0.6969\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6250 - loss: 0.6916\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6865\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6250 - loss: 0.6817\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6769\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8750 - loss: 0.6719\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.6668\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8750 - loss: 0.6615\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.6561\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.6506\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n","Sentence: This is a amazing film., Predicted Class: 1\n","Sentence: I hate this story., Predicted Class: 0\n"]}]}]}